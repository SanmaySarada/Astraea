---
phase: 03-core-mapping-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/astraea/models/mapping.py
  - tests/unit/models/test_mapping.py
autonomous: true

must_haves:
  truths:
    - "All 9 mapping patterns representable as MappingPattern enum"
    - "A VariableMapping captures source, target, pattern, logic, confidence, and CT"
    - "A DomainMappingSpec aggregates all variable mappings for one domain"
    - "LLM output schema (DomainMappingProposal) is a simpler subset of the full spec"
    - "Confidence levels derived from numeric scores with correct thresholds"
  artifacts:
    - path: "src/astraea/models/mapping.py"
      provides: "Mapping specification Pydantic models"
      contains: "class MappingPattern"
    - path: "tests/unit/models/test_mapping.py"
      provides: "Unit tests for mapping models"
      min_lines: 80
  key_links:
    - from: "src/astraea/models/mapping.py"
      to: "src/astraea/models/sdtm.py"
      via: "imports CoreDesignation"
      pattern: "from astraea.models.sdtm import"
---

<objective>
Create all Pydantic data models for the mapping specification -- the contract between the LLM proposal, the validation/enrichment engine, and the output exporters.

Purpose: These models define the exact schema for how mappings are represented throughout the pipeline. Every other Phase 3 component depends on these types.
Output: `src/astraea/models/mapping.py` with all models + comprehensive unit tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-core-mapping-engine/03-RESEARCH.md

@src/astraea/models/sdtm.py
@src/astraea/models/profiling.py
@src/astraea/models/ecrf.py
@src/astraea/models/classification.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create mapping spec Pydantic models</name>
  <files>src/astraea/models/mapping.py</files>
  <action>
Create `src/astraea/models/mapping.py` with these models, following the patterns established in the existing models/ directory (BaseModel + Field descriptions, __future__ annotations, docstrings):

1. **MappingPattern(str, Enum):** 9 values -- ASSIGN, DIRECT, RENAME, REFORMAT, SPLIT, COMBINE, DERIVATION, LOOKUP_RECODE, TRANSPOSE.

2. **ConfidenceLevel(str, Enum):** HIGH, MEDIUM, LOW.

3. **VariableMappingProposal(BaseModel):** The LLM output schema (simpler). Fields:
   - sdtm_variable: str
   - source_dataset: str | None
   - source_variable: str | None
   - mapping_pattern: MappingPattern
   - mapping_logic: str (human-readable description)
   - derivation_rule: str | None (pseudo-code DSL for execution engine)
   - assigned_value: str | None (for ASSIGN pattern)
   - codelist_code: str | None
   - confidence: float (ge=0.0, le=1.0)
   - rationale: str

4. **DomainMappingProposal(BaseModel):** Complete LLM output for a domain. Fields:
   - domain: str
   - variable_proposals: list[VariableMappingProposal]
   - unmapped_source_variables: list[str]
   - suppqual_candidates: list[str]
   - mapping_notes: str

5. **VariableMapping(BaseModel):** The enriched/validated mapping (full spec). Fields:
   - sdtm_variable: str
   - sdtm_label: str
   - sdtm_data_type: Literal["Char", "Num"]
   - core: CoreDesignation (import from models.sdtm)
   - source_dataset: str | None
   - source_variable: str | None
   - source_label: str | None
   - mapping_pattern: MappingPattern
   - mapping_logic: str
   - derivation_rule: str | None
   - assigned_value: str | None
   - codelist_code: str | None
   - codelist_name: str | None
   - confidence: float (ge=0.0, le=1.0)
   - confidence_level: ConfidenceLevel
   - confidence_rationale: str
   - notes: str = ""

6. **DomainMappingSpec(BaseModel):** Complete spec for one domain. Fields:
   - domain: str
   - domain_label: str
   - domain_class: str
   - structure: str
   - study_id: str
   - source_datasets: list[str]
   - cross_domain_sources: list[str] = []
   - variable_mappings: list[VariableMapping]
   - total_variables: int
   - required_mapped: int
   - expected_mapped: int
   - high_confidence_count: int
   - medium_confidence_count: int
   - low_confidence_count: int
   - mapping_timestamp: str
   - model_used: str
   - unmapped_source_variables: list[str] = []
   - suppqual_candidates: list[str] = []

7. **StudyMetadata(BaseModel):** Study-level constants. Fields:
   - study_id: str (e.g., "PHA022121-C301")
   - site_id_variable: str = "SiteNumber"
   - subject_id_variable: str = "Subject"
   - study_env_site_variable: str = "StudyEnvSiteNumber"

8. Add a helper function `confidence_level_from_score(score: float) -> ConfidenceLevel` that returns HIGH if score >= 0.85, MEDIUM if score >= 0.6, else LOW.

Also update `src/astraea/models/__init__.py` to export the new models.
  </action>
  <verify>
    `python -c "from astraea.models.mapping import MappingPattern, VariableMapping, DomainMappingSpec, DomainMappingProposal, StudyMetadata, confidence_level_from_score; print('All models importable')"` succeeds.
  </verify>
  <done>All 8 models defined, importable, and follow existing project patterns.</done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for mapping models</name>
  <files>tests/unit/models/test_mapping.py</files>
  <action>
Create `tests/unit/models/test_mapping.py` with comprehensive tests:

1. **MappingPattern enum:** All 9 values exist, string values match expected lowercase.
2. **ConfidenceLevel enum:** All 3 values exist.
3. **confidence_level_from_score:** Test boundary values -- 0.85 => HIGH, 0.84 => MEDIUM, 0.60 => MEDIUM, 0.59 => LOW, 0.0 => LOW, 1.0 => HIGH.
4. **VariableMappingProposal:** Valid construction, confidence validation (reject >1.0, reject <0.0).
5. **DomainMappingProposal:** Valid construction with list of proposals.
6. **VariableMapping:** Valid construction, all fields set, core field uses CoreDesignation enum.
7. **DomainMappingSpec:** Valid construction, summary count fields present.
8. **StudyMetadata:** Valid construction with defaults, override defaults.
9. **Round-trip JSON:** DomainMappingProposal.model_dump_json() and model_validate_json() produce identical data (critical for LLM tool use).
10. **model_json_schema:** DomainMappingProposal.model_json_schema() produces valid JSON schema (this is what gets sent to Claude as tool definition).

Follow existing test patterns: use pytest, clear test names, fixtures where appropriate.
  </action>
  <verify>`pytest tests/unit/models/test_mapping.py -v` -- all tests pass.</verify>
  <done>Comprehensive tests cover all models, enums, validation, and JSON round-trips.</done>
</task>

</tasks>

<verification>
- `ruff check src/astraea/models/mapping.py tests/unit/models/test_mapping.py` -- no lint errors
- `pytest tests/unit/models/test_mapping.py -v` -- all tests pass
- `python -c "from astraea.models.mapping import DomainMappingProposal; print(DomainMappingProposal.model_json_schema())"` -- produces valid JSON schema for LLM tool use
</verification>

<success_criteria>
All 9 mapping patterns, both LLM and enriched models, confidence scoring, and study metadata are defined as Pydantic models with full validation. JSON schema generation works for LLM tool use.
</success_criteria>

<output>
After completion, create `.planning/phases/03-core-mapping-engine/03-01-SUMMARY.md`
</output>
