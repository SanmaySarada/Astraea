---
phase: 03-core-mapping-engine
plan: 03
type: execute
wave: 2
depends_on: ["03-01", "03-02"]
files_modified:
  - src/astraea/mapping/engine.py
  - src/astraea/mapping/prompts.py
  - src/astraea/mapping/validation.py
  - tests/unit/mapping/test_engine.py
  - tests/unit/mapping/test_validation.py
autonomous: true

must_haves:
  truths:
    - "MappingEngine.map_domain() calls the LLM and returns a validated DomainMappingSpec"
    - "LLM proposals are validated against SDTM-IG (variable exists, correct type)"
    - "CT terms are validated against CTReference (non-extensible exact match)"
    - "Confidence scores are adjusted post-validation (downgrade on CT failure, upgrade on CT pass)"
    - "Proposals are enriched with SDTM-IG labels, core designations, codelist names"
    - "System prompt defines SDTM mapping specialist role with 9 pattern descriptions"
  artifacts:
    - path: "src/astraea/mapping/engine.py"
      provides: "MappingEngine orchestrator"
      contains: "class MappingEngine"
    - path: "src/astraea/mapping/prompts.py"
      provides: "System prompt and instruction templates"
      contains: "MAPPING_SYSTEM_PROMPT"
    - path: "src/astraea/mapping/validation.py"
      provides: "Post-proposal validation and enrichment"
      contains: "def validate_and_enrich"
  key_links:
    - from: "src/astraea/mapping/engine.py"
      to: "src/astraea/llm/client.py"
      via: "AstraeaLLMClient.parse()"
      pattern: "self._llm.parse"
    - from: "src/astraea/mapping/engine.py"
      to: "src/astraea/mapping/context.py"
      via: "MappingContextBuilder.build_prompt()"
      pattern: "build_prompt"
    - from: "src/astraea/mapping/validation.py"
      to: "src/astraea/reference/controlled_terms.py"
      via: "CTReference for CT validation"
      pattern: "ct_ref"
---

<objective>
Build the core mapping engine: the LLM call orchestrator, the system prompt, and the post-proposal validation/enrichment layer.

Purpose: This is the heart of Phase 3 -- the component that takes a domain, calls Claude with structured output, validates the proposal against SDTM-IG and CT, and produces a complete DomainMappingSpec. The LLM proposes WHAT; deterministic code validates HOW.
Output: `engine.py` (orchestrator), `prompts.py` (system prompt), `validation.py` (post-proposal validation) + unit tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-core-mapping-engine/03-RESEARCH.md

@src/astraea/llm/client.py
@src/astraea/reference/sdtm_ig.py
@src/astraea/reference/controlled_terms.py
@src/astraea/models/sdtm.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create system prompt and validation module</name>
  <files>src/astraea/mapping/prompts.py, src/astraea/mapping/validation.py, tests/unit/mapping/test_validation.py</files>
  <action>
**prompts.py:**

Create `src/astraea/mapping/prompts.py` with:

1. **MAPPING_SYSTEM_PROMPT** -- a string constant containing the system prompt for the mapping agent. It should:
   - Define the role: "You are an SDTM mapping specialist with deep knowledge of CDISC SDTM Implementation Guide v3.4"
   - List all 9 mapping patterns with one-line descriptions and examples
   - Instruct: "For each Required and Expected SDTM variable, propose a mapping. Include Permissible variables if source data supports them."
   - Instruct: "For cross-domain derivations, describe the logic and identify the source dataset. You are proposing a SPECIFICATION, not executing transformations."
   - Instruct: "Set confidence 0.9+ for obvious direct/rename matches, 0.7-0.9 for reasonable inference, below 0.7 for uncertain mappings."
   - Instruct: "Identify unmapped source variables and classify them as suppqual_candidates if they contain non-standard clinical data."
   - Instruct: "Use the ASSIGN pattern for STUDYID and DOMAIN (they are constants)."
   - Instruct: "Prefer _STD suffix columns over display columns when CT codelists apply."
   - Do NOT include study-specific details -- those come from the user message (context builder output).

2. **MAPPING_USER_INSTRUCTIONS** -- a string template appended after the context builder output, containing:
   - "Propose mappings for all Required and Expected variables in the {domain} domain."
   - "Include Permissible variables where source data supports them."
   - "For each mapping, specify: sdtm_variable, source, pattern, logic, derivation_rule (if applicable), codelist_code (if applicable), confidence, and rationale."
   - "List any source variables that do not map to a standard {domain} variable in unmapped_source_variables."
   - "Identify non-standard clinical variables that may belong in SUPP{domain} as suppqual_candidates."

**validation.py:**

Create `src/astraea/mapping/validation.py` with:

1. **`validate_and_enrich(proposal: DomainMappingProposal, domain_spec: DomainSpec, ct_ref: CTReference) -> tuple[list[VariableMapping], list[str]]`**
   - Returns (enriched_mappings, validation_issues)
   - For each VariableMappingProposal:
     a. Look up the SDTM variable in domain_spec.variables by name
     b. If not found: add issue "Variable {name} not in SDTM-IG for domain {domain}", still include the mapping but flag
     c. If found: enrich with sdtm_label, sdtm_data_type, core from the VariableSpec
     d. Validate CT: if codelist_code is set, look it up via ct_ref. If codelist not found, add issue and cap confidence at 0.4. If found, codelist_name from codelist. If assigned_value and non-extensible codelist, check term exists.
     e. Apply confidence adjustments per research doc:
        - CT validation passes on lookup_recode: +0.05 (cap at 1.0)
        - Proposed CT term not in codelist: reduce to max 0.4
        - Variable not found in domain spec: reduce to 0.3
     f. Compute confidence_level from adjusted score using confidence_level_from_score()
     g. Build VariableMapping with all enriched fields

2. **`check_required_coverage(mappings: list[VariableMapping], domain_spec: DomainSpec) -> list[str]`**
   - Check that all Req variables in domain_spec have a mapping
   - Return list of missing required variable names

**test_validation.py:**

Create `tests/unit/mapping/test_validation.py` with:
- Test validate_and_enrich with a valid DM proposal (uses real SDTMReference/CTReference)
- Test CT validation: proposal with valid CT term passes, proposal with invalid CT term for non-extensible codelist gets flagged and confidence capped
- Test confidence adjustment: +0.05 for CT pass on lookup_recode
- Test unknown variable: variable not in domain_spec gets confidence 0.3
- Test check_required_coverage: missing STUDYID flagged, all Req present returns empty list
- Use real bundled reference data for realistic tests (SDTMReference, CTReference)
  </action>
  <verify>
    `pytest tests/unit/mapping/test_validation.py -v` -- all tests pass.
    `ruff check src/astraea/mapping/prompts.py src/astraea/mapping/validation.py` -- no lint errors.
  </verify>
  <done>System prompt defines mapping specialist role. Validation module catches CT errors, enriches proposals with SDTM-IG metadata, and adjusts confidence scores.</done>
</task>

<task type="auto">
  <name>Task 2: Create MappingEngine orchestrator</name>
  <files>src/astraea/mapping/engine.py, src/astraea/mapping/__init__.py, tests/unit/mapping/test_engine.py</files>
  <action>
**engine.py:**

Create `src/astraea/mapping/engine.py` with:

1. **MappingEngine class:**
   - Constructor: `__init__(self, llm_client: AstraeaLLMClient, sdtm_ref: SDTMReference, ct_ref: CTReference)`
   - Stores references to all three dependencies + creates a MappingContextBuilder internally

2. **`map_domain()` method:**
   ```python
   def map_domain(
       self,
       domain: str,
       source_profiles: list[DatasetProfile],
       ecrf_forms: list[ECRFForm],
       study_metadata: StudyMetadata,
       cross_domain_profiles: dict[str, DatasetProfile] | None = None,
   ) -> DomainMappingSpec:
   ```
   - Step 1: Get domain_spec from SDTMReference
   - Step 2: Build prompt via MappingContextBuilder.build_prompt()
   - Step 3: Append MAPPING_USER_INSTRUCTIONS (formatted with domain name)
   - Step 4: Call `self._llm.parse(model="claude-sonnet-4-20250514", messages=[{"role": "user", "content": prompt}], system=MAPPING_SYSTEM_PROMPT, output_format=DomainMappingProposal, temperature=0.1, max_tokens=4096)`
   - Step 5: Call validate_and_enrich(proposal, domain_spec, ct_ref)
   - Step 6: Call check_required_coverage to log warnings for missing Req variables
   - Step 7: Build DomainMappingSpec from enriched mappings + metadata
   - Step 8: Log summary via loguru (domain, variables mapped, confidence distribution)
   - Return DomainMappingSpec

3. **`_build_spec()` helper:** Constructs DomainMappingSpec from validated mappings, computing summary counts (total_variables, required_mapped, expected_mapped, high/medium/low_confidence_count) and setting mapping_timestamp (ISO 8601 now) and model_used.

**__init__.py update:**

Update `src/astraea/mapping/__init__.py` to export MappingEngine, MappingContextBuilder.

**test_engine.py:**

Create `tests/unit/mapping/test_engine.py` with:
- **Mock-based tests** (do NOT call real LLM):
  - Create a mock AstraeaLLMClient that returns a predefined DomainMappingProposal for DM
  - Test `map_domain()` with the mock: verify it returns a DomainMappingSpec with correct domain, study_id, and enriched mappings
  - Test that summary counts are computed correctly (high/medium/low counts)
  - Test that mapping_timestamp is valid ISO 8601
  - Test that model_used is set
  - Test that required coverage check runs (mock with missing STUDYID to verify warning logged)
- Use real SDTMReference and CTReference (bundled data) so enrichment is realistic
- The mock DomainMappingProposal should include at least 5 variable proposals covering different patterns: ASSIGN (STUDYID), DIRECT (AGE), RENAME (SEX from SEX_STD), DERIVATION (RFSTDTC), LOOKUP_RECODE (ETHNIC)
  </action>
  <verify>
    `pytest tests/unit/mapping/test_engine.py -v` -- all tests pass.
    `pytest tests/unit/mapping/ -v` -- all mapping tests pass.
    `ruff check src/astraea/mapping/` -- no lint errors.
  </verify>
  <done>MappingEngine orchestrates LLM call -> validation -> enrichment -> spec construction. Mock-based tests verify the full flow without API calls.</done>
</task>

</tasks>

<verification>
- `ruff check src/astraea/mapping/ tests/unit/mapping/` -- no lint errors
- `pytest tests/unit/mapping/ -v` -- all tests pass
- `pytest tests/ -x -q` -- full test suite still passes
</verification>

<success_criteria>
MappingEngine.map_domain() produces a validated, enriched DomainMappingSpec from an LLM proposal. CT validation catches invalid terms. Confidence adjustments work correctly. All without making real API calls in tests.
</success_criteria>

<output>
After completion, create `.planning/phases/03-core-mapping-engine/03-03-SUMMARY.md`
</output>
