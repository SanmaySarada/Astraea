---
phase: 04-human-review-gate
plan: 03
type: execute
wave: 3
depends_on: ["04-02"]
files_modified:
  - src/astraea/cli/app.py
  - tests/unit/cli/test_review_commands.py
autonomous: false

must_haves:
  truths:
    - "User can run `astraea review-domain <spec-json>` to interactively review a mapping spec"
    - "User can run `astraea resume <session-id>` to continue an interrupted review"
    - "User can run `astraea sessions` to list all review sessions"
    - "Reviewed spec is exported as JSON with corrections applied"
  artifacts:
    - path: "src/astraea/cli/app.py"
      provides: "review-domain, resume, sessions CLI commands"
      contains: "review_domain_cmd"
    - path: "tests/unit/cli/test_review_commands.py"
      provides: "CLI command tests"
  key_links:
    - from: "src/astraea/cli/app.py"
      to: "src/astraea/review/reviewer.py"
      via: "CLI commands call DomainReviewer"
      pattern: "DomainReviewer"
    - from: "src/astraea/cli/app.py"
      to: "src/astraea/review/session.py"
      via: "CLI commands use SessionStore"
      pattern: "SessionStore"
    - from: "src/astraea/cli/app.py"
      to: "src/astraea/review/display.py"
      via: "CLI commands use display functions"
      pattern: "display_session_list|display_review_summary"
---

<objective>
Wire the review module into the CLI as `review-domain`, `resume`, and `sessions` commands, then verify the full interactive flow.

Purpose: These commands make the review gate usable. `review-domain` takes a mapping spec JSON (output of `map-domain`) and starts interactive review. `resume` continues an interrupted session. `sessions` shows all sessions. This completes requirements HITL-01, HITL-02, CLI-02, CLI-03.
Output: Three new CLI commands in `app.py`, tests, human verification of the full flow.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-human-review-gate/04-RESEARCH.md
@.planning/phases/04-human-review-gate/04-01-SUMMARY.md
@.planning/phases/04-human-review-gate/04-02-SUMMARY.md
@src/astraea/cli/app.py
@src/astraea/review/models.py
@src/astraea/review/session.py
@src/astraea/review/reviewer.py
@src/astraea/review/display.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: CLI commands for review workflow</name>
  <files>
    src/astraea/cli/app.py
    tests/unit/cli/test_review_commands.py
  </files>
  <action>
    Add three new commands to `src/astraea/cli/app.py`:

    1. `@app.command(name="review-domain")` -- `review_domain_cmd`:
       - Arguments:
         - spec_file: Path (typer.Argument, help="Path to mapping spec JSON from map-domain")
       - Options:
         - --session: str | None (resume existing session by ID)
         - --db: Path = Path(".astraea/sessions.db") (session database location)
         - --output-dir: Path = Path("output") (where to save reviewed spec)
       - Logic:
         - Load DomainMappingSpec from spec_file via `DomainMappingSpec.model_validate_json(spec_file.read_text())`
         - Create .astraea/ directory if needed
         - If --session provided, load existing session; otherwise create new session with the single domain
         - Instantiate DomainReviewer(session_store, console)
         - Call reviewer.review_domain(session_id, domain)
         - On ReviewInterrupted: print session_id and resume command, exit cleanly (code 0)
         - On completion: export reviewed spec as JSON to output_dir/{domain}_reviewed.json
         - Print review summary (approved/corrected/skipped counts)
         - Close session store

    2. `@app.command(name="resume")` -- `resume_cmd`:
       - Arguments:
         - session_id: str | None = None (typer.Argument, if omitted show most recent)
       - Options:
         - --db: Path = Path(".astraea/sessions.db")
         - --output-dir: Path = Path("output")
       - Logic:
         - Open SessionStore
         - If no session_id, list sessions and pick most recent in_progress
         - Load session
         - Find first domain with status PENDING or IN_PROGRESS
         - If no pending domains, print "Session complete" and exit
         - Instantiate DomainReviewer and call review_domain for the pending domain
         - On ReviewInterrupted: print resume command
         - On completion: advance to next domain, repeat until all done or interrupted
         - Export all completed domain specs to output_dir

    3. `@app.command(name="sessions")` -- `list_sessions_cmd`:
       - Options:
         - --db: Path = Path(".astraea/sessions.db")
         - --study: str | None (filter by study_id)
       - Logic:
         - Open SessionStore
         - Call list_sessions(study_id=study)
         - Display using display_session_list
         - If no sessions, print "No review sessions found."

    Import review modules with lazy imports inside command functions (matching existing pattern in app.py).

    Create `tests/unit/cli/test_review_commands.py`:
    - Use typer.testing.CliRunner to invoke commands
    - Create a temp mapping spec JSON file (minimal valid DomainMappingSpec)
    - Test review-domain with non-existent spec file -> error message, exit code 1
    - Test sessions command with empty database -> "No review sessions found"
    - Test sessions command with a pre-populated database -> shows session table
    - Test resume with no sessions -> appropriate error
    - NOTE: Do NOT test interactive review flow in unit tests (requires terminal input).
      Interactive testing happens in the checkpoint task below.
  </action>
  <verify>
    cd /Users/sanmaysarada/Astraea-SDTM && python -m pytest tests/unit/cli/test_review_commands.py -x -q
    cd /Users/sanmaysarada/Astraea-SDTM && python -m pytest tests/ -x -q
    cd /Users/sanmaysarada/Astraea-SDTM && ruff check src/astraea/cli/app.py src/astraea/review/ tests/unit/review/ tests/unit/cli/test_review_commands.py
  </verify>
  <done>Three CLI commands added and importable, error cases handled, sessions listing works, full test suite passes, ruff clean</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete human review gate: interactive review-domain command with two-tier review (batch approve HIGH, individual review MEDIUM/LOW), correction capture, session persistence, and resume capability.</what-built>
  <how-to-verify>
    1. First, generate a mapping spec if you do not already have one:
       ```
       export ANTHROPIC_API_KEY=sk-...
       astraea map-domain ./Fakedata ./ECRF.pdf DM --output-dir output --cache-dir .cache
       ```

    2. Start a review session:
       ```
       astraea review-domain output/DM_mapping.json --db .astraea/test_sessions.db
       ```
       Expected: See formatted mapping table with Status column, prompted for action.

    3. Choose "review" to enter two-tier mode:
       - Should prompt to batch approve HIGH confidence mappings
       - Should then present MEDIUM/LOW confidence mappings one by one
       - Try approving one, correcting one (change source), and skipping one

    4. Press Ctrl+C or choose "quit" mid-review:
       Expected: Prints session ID and resume command

    5. List sessions:
       ```
       astraea sessions --db .astraea/test_sessions.db
       ```
       Expected: Shows session with status "in_progress"

    6. Resume the session:
       ```
       astraea resume <session-id> --db .astraea/test_sessions.db
       ```
       Expected: Skips already-reviewed variables, continues from where you left off

    7. Complete the review:
       Expected: Reviewed spec exported to output/DM_reviewed.json with corrections applied

    8. Verify the reviewed JSON preserves corrections.
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
cd /Users/sanmaysarada/Astraea-SDTM && python -m pytest tests/ -x -q
cd /Users/sanmaysarada/Astraea-SDTM && ruff check src/ tests/
cd /Users/sanmaysarada/Astraea-SDTM && astraea sessions --db /dev/null 2>&1 || true
</verification>

<success_criteria>
- `astraea review-domain <spec.json>` presents interactive review with formatted table
- Two-tier review: batch approve HIGH, individual review MEDIUM/LOW
- Corrections captured with structured metadata
- Ctrl+C saves state, `astraea resume` continues from exact point
- `astraea sessions` lists all sessions with status
- Reviewed spec exported as JSON with corrections applied
- Full test suite passes (686+ existing + new tests)
- Human verification confirms the complete flow works
</success_criteria>

<output>
After completion, create `.planning/phases/04-human-review-gate/04-03-SUMMARY.md`
</output>
