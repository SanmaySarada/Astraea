---
phase: 09-cli-wiring
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/astraea/cli/app.py
  - tests/unit/cli/test_execute_findings.py
autonomous: true

must_haves:
  truths:
    - "Findings domains (LB, VS, EG) are routed through FindingsExecutor when execute-domain is called"
    - "Non-Findings domains (DM, AE, CM, etc.) still use generic DatasetExecutor unchanged"
    - "SUPPQUAL datasets are generated and written as separate XPT files for Findings domains"
  artifacts:
    - path: "src/astraea/cli/app.py"
      provides: "Findings routing logic in execute-domain command"
      contains: "FindingsExecutor"
    - path: "tests/unit/cli/test_execute_findings.py"
      provides: "Tests for Findings routing in execute-domain"
      min_lines: 60
  key_links:
    - from: "src/astraea/cli/app.py"
      to: "src/astraea/execution/findings.py"
      via: "lazy import + FindingsExecutor instantiation"
      pattern: "FindingsExecutor"
    - from: "src/astraea/cli/app.py"
      to: "src/astraea/execution/suppqual.py"
      via: "SUPPQUAL DataFrame written as supp{domain}.xpt"
      pattern: "supp.*\\.xpt"
---

<objective>
Route Findings domains (LB, VS, EG) through FindingsExecutor in the `execute-domain` CLI command, enabling SUPPQUAL generation in the CLI workflow. Closes GAP-3 from the v1 milestone audit.

Purpose: The FindingsExecutor handles multi-source merging, column normalization, and SUPPQUAL generation for Findings-class domains, but execute-domain currently uses the generic DatasetExecutor for all domains. This means LB/VS/EG domain execution through CLI misses normalization and never generates SUPPQUAL datasets.

Output: Modified `execute-domain` command that detects Findings domains and routes them through FindingsExecutor, writing both the main domain XPT and any SUPPQUAL XPT. Plus unit tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/astraea/cli/app.py
@src/astraea/execution/findings.py
@src/astraea/execution/executor.py
@src/astraea/execution/suppqual.py
@src/astraea/models/suppqual.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Route Findings domains through FindingsExecutor in execute-domain</name>
  <files>src/astraea/cli/app.py</files>
  <action>
Modify the `execute_domain` command function's Step 4 (Executing mapping) to detect Findings domains and route them through FindingsExecutor.

1. Define the Findings domain set at the top of the execute-domain function body (not module level -- keep lazy):
```python
_FINDINGS_DOMAINS = {"LB", "VS", "EG"}
```

2. Replace the current Step 4 execution block. The current code is:
```python
sdtm_ref = load_sdtm_reference()
ct_ref = load_ct_reference()
executor = DatasetExecutor(sdtm_ref=sdtm_ref, ct_ref=ct_ref)
output_dir_path = Path(output_dir)
output_dir_path.mkdir(parents=True, exist_ok=True)
xpt_path = output_dir_path / f"{domain.lower()}.xpt"
executor.execute_to_xpt(spec, raw_dfs, xpt_path, cross_domain=cross_domain)
```

Replace with branching logic:
```python
sdtm_ref = load_sdtm_reference()
ct_ref = load_ct_reference()
output_dir_path = Path(output_dir)
output_dir_path.mkdir(parents=True, exist_ok=True)
xpt_path = output_dir_path / f"{domain.lower()}.xpt"

if domain in _FINDINGS_DOMAINS:
    from astraea.execution.findings import FindingsExecutor
    from astraea.io.xpt_writer import write_xpt

    findings_executor = FindingsExecutor(sdtm_ref=sdtm_ref, ct_ref=ct_ref)

    # Dispatch to domain-specific method
    execute_method = {
        "LB": findings_executor.execute_lb,
        "VS": findings_executor.execute_vs,
        "EG": findings_executor.execute_eg,
    }[domain]

    main_df, supp_df = execute_method(
        spec,
        raw_dfs,
        cross_domain=cross_domain,
        study_id=spec.study_id,
    )

    # Write main domain XPT
    write_xpt(main_df, xpt_path, domain_label=spec.domain_label)
    console.print(f"  Main domain: {len(main_df)} rows -> {xpt_path}")

    # Write SUPPQUAL if generated
    if supp_df is not None and not supp_df.empty:
        supp_xpt_path = output_dir_path / f"supp{domain.lower()}.xpt"
        write_xpt(supp_df, supp_xpt_path, domain_label=f"Supplemental Qualifiers for {domain}")
        console.print(f"  SUPPQUAL: {len(supp_df)} rows -> {supp_xpt_path}")
else:
    executor = DatasetExecutor(sdtm_ref=sdtm_ref, ct_ref=ct_ref)
    executor.execute_to_xpt(spec, raw_dfs, xpt_path, cross_domain=cross_domain)
```

3. Update the summary display at the end to mention SUPPQUAL if it was generated. Add after the existing summary lines:
```python
if domain in _FINDINGS_DOMAINS:
    console.print(f"  Executor: FindingsExecutor (multi-source merge + SUPPQUAL)")
```

4. The FindingsExecutor import MUST be lazy (inside the if block), consistent with the project's CLI import pattern.

IMPORTANT: The `execute_method` calls use keyword args `spec, raw_dfs, cross_domain=, study_id=`. The `study_id` should come from `spec.study_id` if available, falling back to extracting from the first source dataset. Check the FindingsExecutor method signatures -- they accept `study_id: str | None = None`.
  </action>
  <verify>
Run `ruff check src/astraea/cli/app.py` -- zero errors.
Run `python -c "from astraea.cli.app import app; print('OK')"` -- no import errors.
  </verify>
  <done>
execute-domain routes LB/VS/EG through FindingsExecutor with multi-source normalization and SUPPQUAL generation. Non-Findings domains use generic DatasetExecutor unchanged. SUPPQUAL XPT files written alongside main domain XPT.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add unit tests for Findings routing in execute-domain</name>
  <files>tests/unit/cli/test_execute_findings.py</files>
  <action>
Create test file verifying the Findings routing logic in execute-domain. Tests should use mocking to avoid needing real SAS data or XPT I/O for most tests.

Tests to write:

1. `test_execute_domain_lb_uses_findings_executor` -- Create a minimal LB mapping spec JSON (with domain="LB"), a tmp_path with a dummy SAS file. Patch FindingsExecutor.execute_lb to return (pd.DataFrame with STUDYID/DOMAIN/USUBJID, None). Patch write_xpt. Invoke `execute-domain`. Verify FindingsExecutor.execute_lb was called (not DatasetExecutor.execute_to_xpt).

2. `test_execute_domain_eg_uses_findings_executor` -- Same as above but for EG domain. Verify execute_eg is called.

3. `test_execute_domain_dm_uses_generic_executor` -- Create a DM mapping spec. Patch DatasetExecutor.execute_to_xpt. Invoke `execute-domain`. Verify DatasetExecutor was used, NOT FindingsExecutor.

4. `test_execute_domain_lb_with_suppqual` -- Patch FindingsExecutor.execute_lb to return (main_df, supp_df). Verify two XPT files are written: `lb.xpt` and `supplb.xpt`.

5. `test_execute_domain_lb_no_suppqual` -- Patch FindingsExecutor.execute_lb to return (main_df, None). Verify only `lb.xpt` is written, no supplb.xpt.

For the mapping spec JSON fixture, create a minimal valid DomainMappingSpec:
```python
def _make_spec_json(domain: str, tmp_path: Path) -> Path:
    spec = {
        "domain": domain,
        "domain_label": f"{domain} Domain",
        "study_id": "TEST001",
        "source_datasets": ["test.sas7bdat"],
        "variable_mappings": [{
            "sdtm_variable": "STUDYID",
            "mapping_pattern": "ASSIGN",
            "mapping_logic": "TEST001",
            "confidence": 1.0,
        }],
        "mapping_date": "2026-02-27T00:00:00",
        "model_used": "test",
    }
    spec_path = tmp_path / f"{domain.lower()}_spec.json"
    spec_path.write_text(json.dumps(spec))
    return spec_path
```

For the dummy SAS file, create a minimal DataFrame and write it with pyreadstat:
```python
def _make_sas_file(tmp_path: Path, name: str = "test.sas7bdat") -> Path:
    import pyreadstat
    df = pd.DataFrame({"Subject": ["001"], "SiteNumber": ["01"]})
    path = tmp_path / name
    pyreadstat.write_sav(df, str(path))  # or use a simple CSV mock
    return path
```

Actually, since we are testing CLI wiring (not execution correctness), it is cleaner to mock `read_sas_with_metadata` to return a synthetic DataFrame, avoiding real SAS file creation. Use `unittest.mock.patch` on the import location within the function.
  </action>
  <verify>
Run `pytest tests/unit/cli/test_execute_findings.py -x -q` -- all 5 tests pass.
Run `ruff check tests/unit/cli/test_execute_findings.py` -- zero errors.
  </verify>
  <done>
5 tests verify Findings routing: LB uses FindingsExecutor, EG uses FindingsExecutor, DM uses generic executor, LB with SUPPQUAL writes two XPTs, LB without SUPPQUAL writes one XPT.
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/unit/cli/test_execute_findings.py -x -q` -- all 5 tests pass
2. `ruff check src/astraea/cli/app.py tests/unit/cli/test_execute_findings.py` -- zero violations
3. `pytest tests/ -x -q --timeout=120` -- all existing tests still pass
</verification>

<success_criteria>
- execute-domain routes LB, VS, EG through FindingsExecutor
- execute-domain routes all other domains through DatasetExecutor (unchanged behavior)
- SUPPQUAL XPT files are written when FindingsExecutor produces them
- When no SUPPQUAL data exists, only the main domain XPT is written
- GAP-3 from v1-MILESTONE-AUDIT.md is closed
</success_criteria>

<output>
After completion, create `.planning/phases/09-cli-wiring/09-03-SUMMARY.md`
</output>
