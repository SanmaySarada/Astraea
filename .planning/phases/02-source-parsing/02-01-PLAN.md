---
phase: 02-source-parsing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/astraea/models/ecrf.py
  - src/astraea/models/classification.py
  - src/astraea/llm/__init__.py
  - src/astraea/llm/client.py
  - pyproject.toml
  - tests/test_models/test_ecrf.py
  - tests/test_models/test_classification.py
  - tests/test_llm/__init__.py
  - tests/test_llm/test_client.py
autonomous: true

must_haves:
  truths:
    - "ECRFForm and ECRFField models validate eCRF metadata with field names, data types, SAS labels, coded values, and OIDs"
    - "DomainClassification and DomainPlan models capture domain assignment with confidence scores and merge candidates"
    - "AstraeaLLMClient wraps Anthropic SDK with structured output, retry logic, and call logging"
    - "pymupdf4llm and tenacity are installable dependencies"
  artifacts:
    - path: "src/astraea/models/ecrf.py"
      provides: "ECRFField, ECRFForm, ECRFExtractionResult Pydantic models"
      contains: "class ECRFForm"
    - path: "src/astraea/models/classification.py"
      provides: "DomainClassification, DomainPlan, ClassificationResult Pydantic models"
      contains: "class DomainClassification"
    - path: "src/astraea/llm/client.py"
      provides: "AstraeaLLMClient with parse() method"
      contains: "class AstraeaLLMClient"
    - path: "pyproject.toml"
      provides: "Updated dependencies"
      contains: "pymupdf4llm"
  key_links:
    - from: "src/astraea/llm/client.py"
      to: "anthropic"
      via: "Anthropic SDK client.messages.parse()"
      pattern: "messages\\.parse"
    - from: "src/astraea/llm/client.py"
      to: "tenacity"
      via: "retry decorator"
      pattern: "retry"
---

<objective>
Create the Pydantic data models for eCRF metadata and domain classification, plus the shared LLM client wrapper that all Phase 2 LLM calls will use. Also add pymupdf4llm and tenacity to project dependencies.

Purpose: Establishes the data contracts and LLM infrastructure that every subsequent Phase 2 plan depends on.
Output: ecrf.py models, classification.py models, llm/client.py wrapper, updated pyproject.toml
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-source-parsing/02-RESEARCH.md
@src/astraea/models/profiling.py
@src/astraea/models/metadata.py
@src/astraea/models/sdtm.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: eCRF and Classification Pydantic Models</name>
  <files>
    src/astraea/models/ecrf.py
    src/astraea/models/classification.py
    tests/test_models/test_ecrf.py
    tests/test_models/test_classification.py
  </files>
  <action>
Create two new model files following the existing patterns in models/profiling.py and models/metadata.py (BaseModel, Field with descriptions, from __future__ import annotations).

**src/astraea/models/ecrf.py:**
- `ECRFField`: field_number (int), field_name (str, SAS variable name), data_type (str, e.g. "$25", "1", "dd MMM yyyy"), sas_label (str), units (str | None), coded_values (dict[str, str] | None, code->decode pairs like {"Y": "Yes", "N": "No"}), field_oid (str | None)
- `ECRFForm`: form_name (str), fields (list[ECRFField]), page_numbers (list[int], which PDF pages this form spans)
- `ECRFExtractionResult`: forms (list[ECRFForm]), source_pdf (str), extraction_timestamp (str), total_fields (int, computed from forms)

**src/astraea/models/classification.py:**
- `HeuristicScore`: domain (str), score (float 0-1), signals (list[str], what matched e.g. "filename exact match")
- `DomainClassification`: raw_dataset (str), primary_domain (str, domain code or "UNCLASSIFIED"), secondary_domains (list[str]), confidence (float 0-1), reasoning (str), merge_candidates (list[str])
- `DomainPlan`: domain (str), source_datasets (list[str]), mapping_pattern (Literal["direct", "merge", "transpose", "mixed"]), notes (str)
- `ClassificationResult`: classifications (list[DomainClassification]), domain_plans (list[DomainPlan]), unclassified_datasets (list[str])

Update `src/astraea/models/__init__.py` to export the new models.

Write tests validating:
- ECRFField creation with all fields, optional fields as None
- ECRFForm with list of fields, page_numbers
- ECRFField rejects empty field_name
- DomainClassification with confidence bounds (0-1)
- DomainClassification allows "UNCLASSIFIED" as primary_domain
- DomainPlan mapping_pattern constrained to literal values
- ClassificationResult with empty unclassified_datasets
  </action>
  <verify>pytest tests/test_models/test_ecrf.py tests/test_models/test_classification.py -v</verify>
  <done>All model tests pass. ECRFForm, ECRFField, DomainClassification, DomainPlan, ClassificationResult models exist with proper validation.</done>
</task>

<task type="auto">
  <name>Task 2: LLM Client Wrapper and Dependencies</name>
  <files>
    src/astraea/llm/__init__.py
    src/astraea/llm/client.py
    tests/test_llm/__init__.py
    tests/test_llm/test_client.py
    pyproject.toml
  </files>
  <action>
**pyproject.toml:** Add `pymupdf4llm>=0.3.4`, `pdfplumber>=0.11`, and `tenacity>=9.0` to the dependencies list. Run `pip install -e ".[dev]"` to install.

**src/astraea/llm/__init__.py:** Export AstraeaLLMClient.

**src/astraea/llm/client.py:** Create the shared LLM client wrapper per the research recommendations:
- `AstraeaLLMClient` class wrapping `anthropic.Anthropic()`
- `parse()` method accepting: model (str), messages (list[dict]), output_format (type[T] where T is a Pydantic BaseModel), max_tokens (int, default 4096), temperature (float, default 0.1), system (str | None)
- Uses `client.messages.parse()` for structured output (GA API, NOT beta)
- Retry with tenacity: `@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=30), retry=retry_if_exception_type((anthropic.APITimeoutError, anthropic.APIConnectionError, anthropic.RateLimitError)))`
- Log every call with loguru: model, temperature, input_tokens, output_tokens, latency in seconds
- Returns `T` (the parsed Pydantic model instance)
- Handle `anthropic.BadRequestError` WITHOUT retry (don't retry on 400s)
- Type hint the method properly using TypeVar bound to BaseModel

**tests/test_llm/test_client.py:** Test WITHOUT real API calls:
- Test that AstraeaLLMClient can be instantiated (mock the Anthropic client)
- Test that parse() calls client.messages.parse() with correct arguments (mock)
- Test that retry decorator is applied (check the function is wrapped)
- Do NOT test actual API calls -- those are integration tests

IMPORTANT: Use `from unittest.mock import patch, MagicMock` for mocking. Do not require ANTHROPIC_API_KEY for unit tests.
  </action>
  <verify>pip install -e ".[dev]" && pytest tests/test_llm/ -v && python -c "from astraea.llm import AstraeaLLMClient; print('LLM client importable')"</verify>
  <done>LLM client wrapper exists with retry logic and logging. pymupdf4llm and tenacity are installed. All unit tests pass without requiring API key.</done>
</task>

</tasks>

<verification>
1. `pytest tests/test_models/test_ecrf.py tests/test_models/test_classification.py tests/test_llm/ -v` -- all tests pass
2. `python -c "from astraea.models.ecrf import ECRFForm, ECRFField; from astraea.models.classification import DomainClassification, DomainPlan; print('Models OK')"` -- imports work
3. `python -c "from astraea.llm import AstraeaLLMClient; print('LLM client OK')"` -- import works
4. `python -c "import pymupdf4llm; import tenacity; print('Dependencies OK')"` -- new deps installed
5. `ruff check src/astraea/models/ecrf.py src/astraea/models/classification.py src/astraea/llm/` -- no lint errors
</verification>

<success_criteria>
- ECRFForm, ECRFField, ECRFExtractionResult models exist and validate correctly
- DomainClassification, DomainPlan, ClassificationResult models exist and validate correctly
- AstraeaLLMClient wraps Anthropic SDK with structured output, retry, and logging
- pymupdf4llm and tenacity are installable project dependencies
- All tests pass, all imports work, no lint errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-source-parsing/02-01-SUMMARY.md`
</output>
