---
phase: 02-source-parsing
plan: 04
type: execute
wave: 3
depends_on: ["02-02", "02-03"]
files_modified:
  - src/astraea/parsing/form_dataset_matcher.py
  - src/astraea/classification/classifier.py
  - tests/test_parsing/test_form_dataset_matcher.py
  - tests/test_classification/test_classifier.py
autonomous: true

must_haves:
  truths:
    - "System associates eCRF forms with raw datasets by variable name overlap"
    - "System classifies each raw dataset to an SDTM domain using heuristic + LLM fusion"
    - "System detects multi-dataset merges into single SDTM domains"
    - "System provides confidence score and reasoning for each classification"
    - "System returns UNCLASSIFIED for datasets that don't map to standard domains"
  artifacts:
    - path: "src/astraea/parsing/form_dataset_matcher.py"
      provides: "match_form_to_datasets() and match_all_forms() functions"
      contains: "def match_form_to_datasets"
    - path: "src/astraea/classification/classifier.py"
      provides: "classify_dataset() and classify_all() functions"
      contains: "def classify_all"
  key_links:
    - from: "src/astraea/parsing/form_dataset_matcher.py"
      to: "src/astraea/models/ecrf.py"
      via: "ECRFForm fields matched to DatasetProfile variables"
      pattern: "ECRFForm"
    - from: "src/astraea/classification/classifier.py"
      to: "src/astraea/llm/client.py"
      via: "AstraeaLLMClient.parse() for LLM classification"
      pattern: "client\\.parse"
    - from: "src/astraea/classification/classifier.py"
      to: "src/astraea/classification/heuristic.py"
      via: "compute_heuristic_scores() for sanity checking"
      pattern: "compute_heuristic_scores"
    - from: "src/astraea/classification/classifier.py"
      to: "src/astraea/models/classification.py"
      via: "Returns ClassificationResult"
      pattern: "ClassificationResult"
---

<objective>
Build the form-to-dataset matcher and LLM-based domain classifier that fuses heuristic scores with Claude reasoning to produce final domain classifications with confidence scores and merge plans.

Purpose: Fulfills ECRF-03 (associate forms with datasets), CLSF-01 (classify datasets), CLSF-03 (detect merges), CLSF-04 (confidence + reasoning). This is the "understanding the source" layer.
Output: form_dataset_matcher.py, classifier.py with tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/02-source-parsing/02-RESEARCH.md
@src/astraea/models/ecrf.py
@src/astraea/models/classification.py
@src/astraea/models/profiling.py
@src/astraea/classification/heuristic.py
@src/astraea/llm/client.py
@src/astraea/parsing/ecrf_parser.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Form-to-Dataset Matcher</name>
  <files>
    src/astraea/parsing/form_dataset_matcher.py
    tests/test_parsing/test_form_dataset_matcher.py
  </files>
  <action>
**src/astraea/parsing/form_dataset_matcher.py:**

`match_form_to_datasets(form: ECRFForm, profiles: list[DatasetProfile]) -> list[tuple[str, float]]`:
- Get field names from ECRFForm (uppercase)
- For each DatasetProfile, get clinical (non-EDC) variable names (uppercase)
- Compute overlap: len(form_fields & clinical_vars) / len(form_fields) if form_fields else 0
- Only include datasets with overlap > 0.0
- Return sorted by score descending: list of (dataset_filename, overlap_score)

`match_all_forms(forms: list[ECRFForm], profiles: list[DatasetProfile], threshold: float = 0.2) -> dict[str, list[tuple[str, float]]]`:
- For each form, call match_form_to_datasets
- Filter results to only include matches above threshold
- Return dict of form_name -> [(dataset_name, score), ...]
- Log: "Matched form '{form_name}' to {n} dataset(s)"

`get_unmatched_datasets(form_matches: dict[str, list[tuple[str, float]]], all_dataset_names: list[str]) -> list[str]`:
- Returns dataset names that appear in no form match
- These are datasets without eCRF form association

`get_unmatched_forms(form_matches: dict[str, list[tuple[str, float]]]) -> list[str]`:
- Returns form names with zero dataset matches
- These are eCRF forms with no corresponding raw data

**Tests (test_form_dataset_matcher.py):**
- Create mock ECRFForm with fields AETERM, AESTDTC, AEENDTC
- Create mock DatasetProfile with variables AETERM, AESTDTC, AEENDTC, projectid (EDC)
- Test match_form_to_datasets returns high score for matching dataset
- Test match_form_to_datasets returns low/no score for non-matching dataset
- Test match_all_forms with threshold filtering
- Test get_unmatched_datasets identifies datasets with no form match
- Test get_unmatched_forms identifies forms with no dataset match
  </action>
  <verify>pytest tests/test_parsing/test_form_dataset_matcher.py -v</verify>
  <done>Form-dataset matcher associates eCRF forms with raw datasets by variable overlap. All tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: LLM Domain Classifier with Heuristic Fusion</name>
  <files>
    src/astraea/classification/classifier.py
    tests/test_classification/test_classifier.py
  </files>
  <action>
**src/astraea/classification/classifier.py:**

Internal Pydantic model for LLM output (not exported):
`_LLMClassificationOutput(BaseModel)`: primary_domain (str), secondary_domains (list[str]), confidence (float, 0-1), reasoning (str), merge_candidates (list[str])

`CLASSIFICATION_PROMPT`: Template prompt per research Example 4:
- Lists available SDTM domains
- Includes dataset name, row count, clinical variable summary (name + label, first 30 vars)
- Includes eCRF form association if known (form name and field count)
- Includes heuristic scores for reference ("Heuristic suggests: AE (1.0), ...")
- Instructs to use "UNCLASSIFIED" if no standard domain fits
- Instructs to list merge_candidates if this dataset should combine with others

`classify_dataset(dataset_name: str, profile: DatasetProfile, heuristic_scores: list[HeuristicScore], ecrf_form_name: str | None, client: AstraeaLLMClient, ref: SDTMReference) -> DomainClassification`:
- Build prompt from template with dataset context
- Call client.parse() with model="claude-sonnet-4-20250514", temperature=0.1, output_format=_LLMClassificationOutput
- If top heuristic score >= 0.9 AND LLM agrees, use confidence = max(heuristic, llm_confidence)
- If heuristic and LLM DISAGREE AND heuristic score >= 0.8, log warning and flag for review (set confidence = min of both * 0.7)
- Return DomainClassification with dataset_name, domain, confidence, reasoning

`classify_all(profiles: list[DatasetProfile], ecrf_result: ECRFExtractionResult | None, form_matches: dict[str, list[tuple[str, float]]] | None, client: AstraeaLLMClient | None, ref: SDTMReference | None) -> ClassificationResult`:
- Orchestrator function. Creates client and ref if None.
- For each profile, compute heuristic scores, find associated eCRF form (if available), then call classify_dataset
- After individual classification, call detect_merge_groups on all dataset names
- Cross-reference LLM merge_candidates with heuristic merge_groups
- Build DomainPlan objects: for each unique domain, list all source datasets and determine mapping_pattern ("direct" for single dataset, "merge" for multi-dataset, "transpose" for Findings class, "mixed" for merge+transpose)
- Collect unclassified datasets
- Return ClassificationResult with all classifications, domain plans, and unclassified list
- Log summary: "Classified {n} datasets to {m} domains, {k} unclassified"

`save_classification(result: ClassificationResult, output_path: str | Path) -> None`:
- Saves ClassificationResult as JSON for caching

`load_classification(path: str | Path) -> ClassificationResult`:
- Loads cached ClassificationResult from JSON

**Tests (test_classifier.py):**
- Test classify_dataset with mocked LLM client returning a known classification
- Test heuristic-LLM agreement (high heuristic + LLM agrees = high confidence)
- Test heuristic-LLM disagreement (high heuristic + LLM disagrees = flagged, lower confidence)
- Test classify_all orchestrator with mocked dependencies (3 datasets, one unclassified)
- Test DomainPlan creation: single dataset -> "direct", multiple datasets -> "merge"
- Test save/load classification round-trip
- All tests use mocks, do NOT require ANTHROPIC_API_KEY
  </action>
  <verify>pytest tests/test_classification/ -v</verify>
  <done>Domain classifier fuses heuristic scores with LLM reasoning. Merge detection works. Confidence scoring reflects agreement level. All tests pass without API key.</done>
</task>

</tasks>

<verification>
1. `pytest tests/test_parsing/test_form_dataset_matcher.py tests/test_classification/ -v` -- all tests pass
2. `python -c "from astraea.parsing.form_dataset_matcher import match_all_forms; print('Matcher OK')"` -- imports
3. `python -c "from astraea.classification.classifier import classify_all; print('Classifier OK')"` -- imports
4. `ruff check src/astraea/parsing/ src/astraea/classification/` -- no lint errors
</verification>

<success_criteria>
- Form-dataset matcher associates eCRF forms with raw datasets by variable overlap
- LLM classifier uses heuristic scores as context and sanity check
- Heuristic-LLM disagreement is flagged with reduced confidence
- Multi-dataset merges are detected and reflected in DomainPlan objects
- UNCLASSIFIED path works for ambiguous datasets
- All tests pass without API key
</success_criteria>

<output>
After completion, create `.planning/phases/02-source-parsing/02-04-SUMMARY.md`
</output>
