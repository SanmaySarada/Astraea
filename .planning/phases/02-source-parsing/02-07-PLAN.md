---
phase: 02-source-parsing
plan: 07
type: execute
wave: 1
depends_on: []
files_modified:
  - src/astraea/data/sdtm_ig/domains.json
  - src/astraea/classification/classifier.py
  - tests/test_reference/test_sdtm_ig.py
  - tests/test_classification/test_classifier.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "SDTMReference.list_domains() returns at least 18 domains including CE, DA, DV, PE, QS, SC, SV, FA"
    - "Variable overlap scoring works for all 18+ domains (not just 10)"
    - "When heuristic score >= 0.95 and disagrees with LLM, heuristic domain is used"
    - "LLM classifier available_domains list includes all bundled domains"
  artifacts:
    - path: "src/astraea/data/sdtm_ig/domains.json"
      provides: "SDTM-IG specs for 18+ domains"
    - path: "src/astraea/classification/classifier.py"
      provides: "Heuristic override logic for score >= 0.95"
      contains: "0.95"
    - path: "tests/test_reference/test_sdtm_ig.py"
      provides: "Tests verifying new domains are loadable"
    - path: "tests/test_classification/test_classifier.py"
      provides: "Tests for heuristic override behavior"
  key_links:
    - from: "src/astraea/classification/classifier.py"
      to: "src/astraea/reference/sdtm_ig.py"
      via: "ref.list_domains() for available_domains in prompt"
      pattern: "ref\\.list_domains"
    - from: "src/astraea/classification/classifier.py"
      to: "heuristic_scores"
      via: "heuristic override at 0.95 threshold"
      pattern: "0\\.95"
---

<objective>
Expand SDTM-IG reference bundle with missing domains (Gap 2) and add heuristic override logic for very high confidence scores (Gap 5).

Purpose: The reference bundle only has 10 domains, limiting variable overlap scoring and LLM available_domains. The classifier also lets LLM override strong heuristic signals, risking hallucination cascading (Pitfall C1).

Output: Complete domains.json with 18+ SDTM domains, classifier with heuristic override at 0.95 threshold, and tests for both.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@src/astraea/reference/sdtm_ig.py
@src/astraea/data/sdtm_ig/domains.json
@src/astraea/classification/classifier.py
@src/astraea/models/sdtm.py
@tests/test_reference/test_sdtm_ig.py
@tests/test_classification/test_classifier.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Expand SDTM-IG domains.json with missing domain specs</name>
  <files>src/astraea/data/sdtm_ig/domains.json, tests/test_reference/test_sdtm_ig.py</files>
  <action>
  Add the following domains to domains.json, following the exact same structure as existing entries (domain, description, domain_class, structure, variables array with name/label/data_type/core/codelist/role/order fields).

  Use SDTM-IG v3.4 specifications for each domain. The domain_class values must be one of: "Events", "Findings", "Interventions", "Special Purpose", "Trial Design".

  Domains to add (8 new domains):

  1. **CE** (Clinical Events): domain_class="Events", structure="One record per event per subject"
     Key variables: STUDYID, DOMAIN, USUBJID, CESEQ, CETERM, CEDECOD, CECAT, CESCAT, CEPRESP, CEOCCUR, CESTDTC, CEENDTC, CEDY

  2. **DV** (Protocol Deviations): domain_class="Events", structure="One record per deviation per subject"
     Key variables: STUDYID, DOMAIN, USUBJID, DVSEQ, DVTERM, DVDECOD, DVCAT, DVSCAT, DVSTDTC, DVENDTC

  3. **PE** (Physical Examination): domain_class="Findings", structure="One record per finding per visit per subject"
     Key variables: STUDYID, DOMAIN, USUBJID, PESEQ, PETESTCD, PETEST, PECAT, PEORRES, PESTRESC, PELOC, PEDTC, PEDY

  4. **QS** (Questionnaires): domain_class="Findings", structure="One record per question per visit per subject"
     Key variables: STUDYID, DOMAIN, USUBJID, QSSEQ, QSTESTCD, QSTEST, QSCAT, QSSCAT, QSORRES, QSORRESU, QSSTRESC, QSSTRESN, QSSTRESU, QSDTC

  5. **SC** (Subject Characteristics): domain_class="Findings", structure="One record per characteristic per subject"
     Key variables: STUDYID, DOMAIN, USUBJID, SCSEQ, SCTESTCD, SCTEST, SCORRES, SCSTRESC, SCSTRESN

  6. **FA** (Findings About): domain_class="Findings", structure="One record per finding per subject"
     Key variables: STUDYID, DOMAIN, USUBJID, FASEQ, FATESTCD, FATEST, FAOBJ, FACAT, FAORRES, FASTRESC, FADTC

  7. **SV** (Subject Visits): domain_class="Special Purpose", structure="One record per visit per subject"
     Key variables: STUDYID, DOMAIN, USUBJID, VISITNUM, VISIT, VISITDY, SVSTDTC, SVENDTC

  8. **DA** (Drug Accountability): domain_class="Interventions", structure="One record per dispensation per subject"
     Key variables: STUDYID, DOMAIN, USUBJID, DASEQ, DATESTCD, DATEST, DAORRES, DAORRESU, DASTRESC, DASTRESN, DADTC

  For each variable, set appropriate core designations:
  - STUDYID, DOMAIN, USUBJID: core="Req"
  - --SEQ: core="Req"
  - --TESTCD, --TEST (Findings): core="Req"
  - --TERM, --DECOD (Events): core="Req" for TERM, "Exp" for DECOD
  - Most others: core="Exp" or "Perm"

  Set data_type: "Char" for text, "Num" for numeric, "Char" for dates (ISO 8601 stored as char in SDTM).
  Set role: "Identifier" for STUDYID/DOMAIN/USUBJID, "Topic" for --TERM/--TESTCD, "Record Qualifier" for most others, "Timing" for date variables.
  Set codelist to null unless you know the specific CDISC CT codelist.

  After adding, verify the JSON is valid and loads correctly.

  Then add a test in test_sdtm_ig.py that verifies:
  - `ref.list_domains()` returns at least 18 domains
  - Each new domain is loadable via `ref.get_domain_spec("CE")` etc.
  - Each new domain has at least 5 variables
  - Domain classes are correct (CE=Events, QS=Findings, SV=Special Purpose, DA=Interventions)
  </action>
  <verify>
  Run: `cd /Users/sanmaysarada/Astraea-SDTM && python -c "from astraea.reference.sdtm_ig import SDTMReference; r=SDTMReference(); print(len(r.list_domains()), r.list_domains())"`
  Expected: 18 domains listed including all new ones.
  Run: `pytest tests/test_reference/test_sdtm_ig.py -v --tb=short`
  </verify>
  <done>domains.json contains 18+ domains. SDTMReference loads all of them. Tests verify each new domain's structure and class.</done>
</task>

<task type="auto">
  <name>Task 2: Add heuristic override at 0.95 threshold in classifier</name>
  <files>src/astraea/classification/classifier.py, tests/test_classification/test_classifier.py</files>
  <action>
  In `classify_dataset()` function (around lines 186-207), add logic BEFORE the existing heuristic-LLM fusion:

  If `top_heuristic_score >= 0.95` and `top_heuristic_domain` differs from `llm_result.primary_domain`:
  - Use `top_heuristic_domain` as `final_domain` (override LLM)
  - Set `final_confidence` to `top_heuristic_score`
  - Log a warning: "Heuristic override (score={score}): using {h_domain} instead of LLM {l_domain} for {dataset_name}"
  - Skip the rest of the fusion logic (the existing 0.8 threshold check)

  The logic flow should be:
  ```python
  if top_heuristic_score >= 0.95 and top_heuristic_domain is not None and top_heuristic_domain != final_domain:
      # Override LLM with high-confidence heuristic (prevents hallucination cascading)
      logger.warning(...)
      final_domain = top_heuristic_domain
      final_confidence = top_heuristic_score
  elif top_heuristic_score >= 0.9 and top_heuristic_domain == final_domain:
      # Strong agreement: boost
      ...existing code...
  elif top_heuristic_score >= 0.8 and ...:
      # Disagreement with moderate heuristic: penalize
      ...existing code...
  ```

  Add tests in test_classifier.py:
  1. Test heuristic score 1.0 (exact filename match) overrides LLM when they disagree
  2. Test heuristic score 0.95 overrides LLM when they disagree
  3. Test heuristic score 0.8 does NOT override LLM (existing behavior preserved -- only penalizes confidence)
  4. Test heuristic score 0.95 agreeing with LLM uses normal fusion (no override needed)

  Mock the LLM client in tests (follow existing test patterns in the file).
  </action>
  <verify>
  Run: `cd /Users/sanmaysarada/Astraea-SDTM && pytest tests/test_classification/test_classifier.py -v --tb=short`
  All tests pass including new override tests.
  </verify>
  <done>Classifier overrides LLM with heuristic domain when heuristic >= 0.95 and disagrees. Existing 0.8 penalty behavior unchanged. Tests cover all threshold scenarios.</done>
</task>

</tasks>

<verification>
1. `pytest tests/test_reference/test_sdtm_ig.py tests/test_classification/test_classifier.py -v` -- all pass
2. `ruff check src/astraea/data/sdtm_ig/ src/astraea/classification/classifier.py` -- no lint errors
3. `python -c "from astraea.reference.sdtm_ig import SDTMReference; r=SDTMReference(); assert len(r.list_domains()) >= 18"`
</verification>

<success_criteria>
- domains.json has 18+ domains (was 10)
- SDTMReference exposes all new domains via list_domains() and get_domain_spec()
- Classifier overrides LLM when heuristic >= 0.95 and disagrees
- Classifier preserves existing 0.8-threshold penalty behavior
- All existing + new tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-source-parsing/02-07-SUMMARY.md`
</output>
