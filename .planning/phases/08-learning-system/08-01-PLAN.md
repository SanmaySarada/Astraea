---
phase: 08-learning-system
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/astraea/learning/__init__.py
  - src/astraea/learning/models.py
  - src/astraea/learning/example_store.py
  - src/astraea/learning/vector_store.py
  - tests/unit/learning/test_models.py
  - tests/unit/learning/test_example_store.py
  - tests/unit/learning/test_vector_store.py
autonomous: true

must_haves:
  truths:
    - "Mapping examples can be stored with full metadata (study, domain, variable, pattern, confidence, correction status)"
    - "Corrections can be stored as original/corrected pairs with human reason"
    - "Similar past mappings can be retrieved by semantic similarity filtered by domain"
    - "All stores persist to disk and survive process restarts"
  artifacts:
    - path: "src/astraea/learning/models.py"
      provides: "MappingExample, CorrectionRecord, StudyMetrics Pydantic models"
      exports: ["MappingExample", "CorrectionRecord", "StudyMetrics"]
    - path: "src/astraea/learning/example_store.py"
      provides: "SQLite-backed structured storage for mapping examples and corrections"
      exports: ["ExampleStore"]
    - path: "src/astraea/learning/vector_store.py"
      provides: "ChromaDB wrapper for semantic similarity search"
      exports: ["LearningVectorStore"]
  key_links:
    - from: "src/astraea/learning/models.py"
      to: "src/astraea/models/mapping.py"
      via: "imports VariableMapping for original/corrected mapping fields"
      pattern: "from astraea\\.models\\.mapping import"
    - from: "src/astraea/learning/example_store.py"
      to: "src/astraea/learning/models.py"
      via: "uses MappingExample and CorrectionRecord for storage"
      pattern: "from astraea\\.learning\\.models import"
    - from: "src/astraea/learning/vector_store.py"
      to: "chromadb"
      via: "PersistentClient for vector storage"
      pattern: "chromadb\\.PersistentClient"
---

<objective>
Create the foundational data models and storage layer for the learning system: Pydantic models for mapping examples and corrections, a SQLite-backed example store for structured data, and a ChromaDB vector store for semantic similarity search.

Purpose: These are the data foundations that all other learning system components build on. Without persistent storage for examples and semantic retrieval, no learning can happen.
Output: Three modules (models.py, example_store.py, vector_store.py) with full test coverage.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-learning-system/08-RESEARCH.md

@src/astraea/review/models.py
@src/astraea/review/session.py
@src/astraea/models/mapping.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pydantic models for learning system data</name>
  <files>
    src/astraea/learning/__init__.py
    src/astraea/learning/models.py
    tests/unit/learning/__init__.py
    tests/unit/learning/test_models.py
  </files>
  <action>
    Create `src/astraea/learning/__init__.py` (empty).
    Create `tests/unit/learning/__init__.py` (empty).

    Create `src/astraea/learning/models.py` with these Pydantic models:

    1. **MappingExample(BaseModel)** -- a single approved/corrected variable mapping from a completed review:
       - `example_id: str` (UUID, default_factory)
       - `study_id: str`
       - `domain: str`
       - `sdtm_variable: str`
       - `mapping_pattern: str` (from MappingPattern enum values)
       - `mapping_logic: str`
       - `source_variable: str | None = None`
       - `source_dataset: str | None = None`
       - `source_label: str | None = None`
       - `confidence: float`
       - `was_corrected: bool = False`
       - `final_mapping_json: str` (serialized VariableMapping)
       - `created_at: str` (ISO 8601, default_factory using UTC now)

    2. **CorrectionRecord(BaseModel)** -- an original-to-corrected mapping pair:
       - `correction_id: str` (UUID, default_factory)
       - `study_id: str`
       - `session_id: str`
       - `domain: str`
       - `sdtm_variable: str`
       - `correction_type: str` (from CorrectionType enum values)
       - `original_pattern: str`
       - `corrected_pattern: str | None = None`
       - `original_logic: str`
       - `corrected_logic: str | None = None`
       - `reason: str`
       - `created_at: str` (ISO 8601, default_factory)
       - `invalidated: bool = False` (for poisoning protection per RESEARCH.md pitfall 2)

    3. **StudyMetrics(BaseModel)** -- per-domain per-study accuracy tracking:
       - `study_id: str`
       - `domain: str`
       - `total_proposed: int`
       - `approved_unchanged: int`
       - `corrected: int`
       - `rejected: int`
       - `added_by_reviewer: int`
       - `accuracy_rate: float` (computed: approved_unchanged / total_proposed)
       - `correction_rate: float` (computed: corrected / total_proposed)
       - `completed_at: str`

    4. **Helper function `mapping_to_embedding_text()`** -- converts mapping metadata to a natural language string for ChromaDB embedding (NOT raw JSON, per RESEARCH.md anti-pattern). Takes domain, sdtm_variable, mapping_pattern, mapping_logic, source_variable (optional), source_label (optional). Returns structured sentence like "SDTM domain AE variable AETERM. mapping pattern: direct. logic: Direct carry from source. source variable: AETERM. source label: Reported Term".

    Tests in `tests/unit/learning/test_models.py`:
    - MappingExample creation with defaults (UUID generated, timestamp set)
    - CorrectionRecord creation and invalidation flag
    - StudyMetrics with accuracy/correction rate calculation
    - mapping_to_embedding_text with full args
    - mapping_to_embedding_text with optional args omitted
    - MappingExample round-trip (model_dump_json / model_validate_json)
  </action>
  <verify>pytest tests/unit/learning/test_models.py -v passes all tests</verify>
  <done>All 3 Pydantic models created with type hints, all tests pass, ruff clean</done>
</task>

<task type="auto">
  <name>Task 2: SQLite example store and ChromaDB vector store</name>
  <files>
    src/astraea/learning/example_store.py
    src/astraea/learning/vector_store.py
    tests/unit/learning/test_example_store.py
    tests/unit/learning/test_vector_store.py
  </files>
  <action>
    Create `src/astraea/learning/example_store.py` with class **ExampleStore**:
    - `__init__(self, db_path: Path)` -- opens/creates SQLite DB, creates tables if needed. Follow SessionStore pattern (sqlite3.Row factory, parent mkdir).
    - Tables:
      - `mapping_examples`: id, example_id (TEXT UNIQUE), study_id, domain, sdtm_variable, mapping_pattern, mapping_logic, source_variable, source_dataset, source_label, confidence, was_corrected, final_mapping_json, created_at
      - `corrections`: id, correction_id (TEXT UNIQUE), study_id, session_id, domain, sdtm_variable, correction_type, original_pattern, corrected_pattern, original_logic, corrected_logic, reason, created_at, invalidated (INTEGER DEFAULT 0)
      - `study_metrics`: id, study_id, domain, total_proposed, approved_unchanged, corrected, rejected, added_by_reviewer, accuracy_rate, correction_rate, completed_at, UNIQUE(study_id, domain)
    - Methods:
      - `save_example(example: MappingExample) -> None`
      - `save_correction(correction: CorrectionRecord) -> None`
      - `save_metrics(metrics: StudyMetrics) -> None`
      - `get_examples_for_domain(domain: str, limit: int = 50) -> list[MappingExample]`
      - `get_corrections_for_domain(domain: str, include_invalidated: bool = False) -> list[CorrectionRecord]`
      - `get_study_metrics(study_id: str | None = None) -> list[StudyMetrics]`
      - `invalidate_correction(correction_id: str) -> None`
      - `get_example_count() -> int`
      - `get_correction_count() -> int`
      - `close() -> None`

    Create `src/astraea/learning/vector_store.py` with class **LearningVectorStore**:
    - `__init__(self, persist_dir: Path)` -- creates ChromaDB PersistentClient at persist_dir. Creates two collections: "approved_mappings" and "corrections".
    - `add_example(example: MappingExample) -> None` -- converts to embedding text via `mapping_to_embedding_text()`, adds to approved_mappings collection with metadata (study_id, domain, sdtm_variable, mapping_pattern, was_corrected as str, confidence).
    - `add_correction(correction: CorrectionRecord) -> None` -- converts to embedding text using original+corrected logic, adds to corrections collection with metadata (study_id, domain, sdtm_variable, correction_type, original_pattern, corrected_pattern).
    - `query_similar_mappings(domain: str, query_text: str, n_results: int = 5) -> list[dict]` -- queries approved_mappings with domain metadata filter, returns list of dicts with keys: document, metadata, distance.
    - `query_similar_corrections(domain: str, query_text: str, n_results: int = 3) -> list[dict]` -- queries corrections with domain filter and `invalidated != "true"` filter, returns list of dicts.
    - `get_collection_counts() -> dict[str, int]` -- returns {"approved_mappings": N, "corrections": M}.
    - `close() -> None` -- no-op for ChromaDB PersistentClient (auto-persists), but included for API consistency.

    IMPORTANT: ChromaDB metadata values must be str, int, float, or bool. Convert Python booleans to str ("true"/"false") for metadata storage.

    Tests in `tests/unit/learning/test_example_store.py` (use tmp_path fixture for SQLite):
    - Save and retrieve example
    - Save and retrieve correction
    - Save and retrieve study metrics
    - get_examples_for_domain filters by domain
    - get_corrections_for_domain excludes invalidated by default
    - invalidate_correction marks as invalidated
    - get_example_count / get_correction_count
    - Duplicate example_id is handled (INSERT OR REPLACE or check)

    Tests in `tests/unit/learning/test_vector_store.py` (use tmp_path fixture for ChromaDB):
    - Add example and query returns it
    - Add correction and query returns it
    - Domain filter works (add AE and DM examples, query AE returns only AE)
    - get_collection_counts returns correct numbers
    - Query with no results returns empty list (graceful empty)

    Note on ChromaDB tests: ChromaDB with PersistentClient may be slow on first initialization (downloads model). Tests should use `chromadb.Client()` (in-memory, ephemeral) for speed, but the production code uses PersistentClient.
  </action>
  <verify>pytest tests/unit/learning/test_example_store.py tests/unit/learning/test_vector_store.py -v passes all tests</verify>
  <done>ExampleStore persists examples/corrections/metrics to SQLite, LearningVectorStore indexes and retrieves by semantic similarity with domain filtering, all tests pass</done>
</task>

</tasks>

<verification>
- `pytest tests/unit/learning/ -v` -- all tests pass
- `ruff check src/astraea/learning/` -- no lint errors
- `python -c "from astraea.learning.models import MappingExample, CorrectionRecord, StudyMetrics; print('imports OK')"` -- imports work
- `python -c "from astraea.learning.example_store import ExampleStore; print('store OK')"` -- imports work
- `python -c "from astraea.learning.vector_store import LearningVectorStore; print('vector OK')"` -- imports work
</verification>

<success_criteria>
- MappingExample, CorrectionRecord, StudyMetrics models exist with correct fields and validation
- ExampleStore reads/writes to SQLite with domain filtering
- LearningVectorStore adds/queries ChromaDB with domain metadata filtering
- All tests pass, ruff clean
</success_criteria>

<output>
After completion, create `.planning/phases/08-learning-system/08-01-SUMMARY.md`
</output>
