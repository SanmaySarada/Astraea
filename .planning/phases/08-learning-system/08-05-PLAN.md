---
phase: 08-learning-system
plan: 05
type: execute
wave: 3
depends_on: ["08-02", "08-03"]
files_modified:
  - src/astraea/learning/dspy_optimizer.py
  - src/astraea/cli/app.py
  - src/astraea/cli/display.py
  - tests/unit/learning/test_dspy_optimizer.py
  - tests/unit/cli/test_learn_commands.py
autonomous: true

must_haves:
  truths:
    - "User can ingest completed review sessions into the learning system via CLI"
    - "User can view learning stats (example counts, accuracy trends) via CLI"
    - "User can trigger DSPy prompt optimization when sufficient examples exist"
    - "DSPy optimizer saves compiled programs to disk for reuse"
  artifacts:
    - path: "src/astraea/learning/dspy_optimizer.py"
      provides: "DSPy BootstrapFewShot integration for prompt optimization"
      exports: ["SDTMMapperModule", "compile_optimizer", "load_compiled_program"]
    - path: "src/astraea/cli/app.py"
      provides: "CLI commands: learn-ingest, learn-stats, learn-optimize"
      contains: "learn-ingest"
  key_links:
    - from: "src/astraea/learning/dspy_optimizer.py"
      to: "dspy"
      via: "BootstrapFewShot optimizer"
      pattern: "dspy\\.BootstrapFewShot"
    - from: "src/astraea/cli/app.py"
      to: "src/astraea/learning/ingestion.py"
      via: "learn-ingest calls ingest_session"
      pattern: "ingest_session"
    - from: "src/astraea/cli/app.py"
      to: "src/astraea/learning/metrics.py"
      via: "learn-stats calls compute_improvement_report"
      pattern: "compute_improvement_report"
---

<objective>
Build the DSPy prompt optimizer and CLI commands for managing the learning system (ingest, stats, optimize).

Purpose: DSPy automates few-shot example selection for optimal mapping quality (Tier 2 learning). CLI commands give the user control over when to ingest, when to optimize, and visibility into accuracy trends.
Output: dspy_optimizer.py + 3 new CLI commands (learn-ingest, learn-stats, learn-optimize).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-learning-system/08-RESEARCH.md

@src/astraea/cli/app.py
@src/astraea/cli/display.py
@src/astraea/learning/ingestion.py
@src/astraea/learning/metrics.py
@src/astraea/learning/example_store.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: DSPy optimizer wrapper</name>
  <files>
    src/astraea/learning/dspy_optimizer.py
    tests/unit/learning/test_dspy_optimizer.py
  </files>
  <action>
    Create `src/astraea/learning/dspy_optimizer.py`:

    1. **SDTMMapperModule(dspy.Module)** -- a DSPy module wrapping the mapping task:
       - `__init__()`: Creates `self.map_variable = dspy.ChainOfThought("domain_spec, source_profile, ecrf_context -> variable_mapping")`
       - `forward(self, domain_spec: str, source_profile: str, ecrf_context: str) -> dspy.Prediction`: Calls self.map_variable with the inputs.

    2. **`build_trainset(example_store: ExampleStore, domain: str | None = None, min_examples: int = 10) -> list[dspy.Example] | None`**:
       - Query example_store for approved examples (optionally filtered by domain).
       - If fewer than min_examples, return None (not enough data for optimization).
       - Convert each MappingExample to a dspy.Example with:
         - domain_spec: f"Domain {example.domain}"
         - source_profile: f"Source: {example.source_variable or 'N/A'} ({example.source_label or 'no label'})"
         - ecrf_context: f"Variable: {example.sdtm_variable}"
         - variable_mapping: f"{example.sdtm_variable} -> {example.mapping_pattern} from {example.source_variable}. Logic: {example.mapping_logic}"
       - Mark inputs: `.with_inputs("domain_spec", "source_profile", "ecrf_context")`
       - Return list of dspy.Example.

    3. **`mapping_accuracy_metric(example: dspy.Example, prediction: dspy.Prediction, trace=None) -> bool`**:
       - Extract sdtm_variable and mapping_pattern from both example.variable_mapping and prediction.variable_mapping.
       - Return True if both variable name and pattern match.
       - Be lenient on exact string matching -- extract the variable name and pattern using simple parsing.

    4. **`compile_optimizer(example_store: ExampleStore, output_path: Path, *, domain: str | None = None, model: str = "anthropic/claude-sonnet-4-20250514", max_rounds: int = 1, max_bootstrapped_demos: int = 4) -> Path | None`**:
       - Build trainset. If None (insufficient data), return None.
       - Configure DSPy: `dspy.configure(lm=dspy.LM(model, temperature=0.1, max_tokens=4096))`
       - Create optimizer: `dspy.BootstrapFewShot(metric=mapping_accuracy_metric, max_bootstrapped_demos=max_bootstrapped_demos, max_rounds=max_rounds)`
       - Compile: `compiled = optimizer.compile(student=SDTMMapperModule(), trainset=trainset)`
       - Save: `compiled.save(str(output_path))`
       - Return output_path.

    5. **`load_compiled_program(program_path: Path) -> SDTMMapperModule | None`**:
       - If program_path does not exist, return None.
       - Load and return: `SDTMMapperModule().load(str(program_path))`

    IMPORTANT: All DSPy imports should be guarded with try/except ImportError so the rest of the learning system works even if dspy is not installed:
    ```python
    try:
        import dspy
        HAS_DSPY = True
    except ImportError:
        HAS_DSPY = False
    ```
    Functions that need DSPy should check HAS_DSPY and raise a clear error if not available.

    Tests in `tests/unit/learning/test_dspy_optimizer.py`:
    - Test build_trainset returns None when fewer than min_examples.
    - Test build_trainset returns list of dspy.Example when sufficient.
    - Test mapping_accuracy_metric returns True on match.
    - Test mapping_accuracy_metric returns False on mismatch.
    - Test load_compiled_program returns None for non-existent path.
    - Skip compile_optimizer test if no ANTHROPIC_API_KEY (mark with pytest.mark.skipif).

    Note: Actual DSPy compilation requires LLM calls and is expensive. Unit tests should test the building blocks (trainset construction, metric function) without running full compilation.
  </action>
  <verify>pytest tests/unit/learning/test_dspy_optimizer.py -v passes all tests</verify>
  <done>DSPy optimizer wrapper builds trainset from example store, metric function evaluates mapping accuracy, compilation and loading work</done>
</task>

<task type="auto">
  <name>Task 2: CLI commands for learning system management</name>
  <files>
    src/astraea/cli/app.py
    src/astraea/cli/display.py
    tests/unit/cli/test_learn_commands.py
  </files>
  <action>
    Add 3 new CLI commands to `src/astraea/cli/app.py`:

    1. **`learn-ingest`** command:
       ```
       astraea learn-ingest --session-db PATH --learning-db PATH [--chroma-dir PATH]
       ```
       - Loads all completed review sessions from session-db (SessionStore).
       - For each completed session, calls ingest_session().
       - Creates ExampleStore at learning-db path, LearningVectorStore at chroma-dir.
       - Default paths: `.astraea/reviews.db` for session-db, `.astraea/learning/examples.db` for learning-db, `.astraea/learning/chroma_db` for chroma-dir.
       - Displays: "Ingested {N} examples and {M} corrections from {K} sessions".
       - Uses lazy imports for learning modules.

    2. **`learn-stats`** command:
       ```
       astraea learn-stats [--learning-db PATH]
       ```
       - Loads ExampleStore.
       - Gets example count, correction count, study metrics.
       - Calls compute_improvement_report() on all metrics.
       - Displays formatted stats using Rich:
         - Total examples, total corrections
         - Per-domain accuracy table (domain, studies, accuracy_rate, correction_rate, trend)
         - Overall improvement summary

    3. **`learn-optimize`** command:
       ```
       astraea learn-optimize --learning-db PATH --output PATH [--domain DOMAIN] [--model MODEL]
       ```
       - Calls compile_optimizer() with the example store.
       - Displays progress and result.
       - Default output: `.astraea/learning/compiled_mapper.json`.
       - If insufficient examples, prints clear message: "Need at least {N} examples for optimization. Currently have {M}."

    Add display helpers to `src/astraea/cli/display.py`:

    4. **`display_learning_stats(report: dict, example_count: int, correction_count: int) -> None`**:
       - Rich table with domain accuracy trends.
       - Summary panel with totals.

    5. **`display_ingestion_result(total_examples: int, total_corrections: int, domains: list[str]) -> None`**:
       - Simple Rich panel with ingestion summary.

    Tests in `tests/unit/cli/test_learn_commands.py`:
    - Test learn-ingest with mock session store (no real sessions) -> "No completed sessions found" message.
    - Test learn-stats with empty learning store -> shows zero counts.
    - Test learn-optimize with insufficient examples -> shows helpful message.
    - Test display_learning_stats produces output (capture console).
    - Test display_ingestion_result produces output.

    Use typer.testing.CliRunner for CLI tests. Mock the learning modules to avoid real ChromaDB/SQLite.
  </action>
  <verify>pytest tests/unit/cli/test_learn_commands.py -v passes all tests && pytest tests/unit/cli/ -v passes (no regressions)</verify>
  <done>3 CLI commands available (learn-ingest, learn-stats, learn-optimize), display helpers work, all existing CLI tests still pass</done>
</task>

</tasks>

<verification>
- `pytest tests/unit/learning/ tests/unit/cli/test_learn_commands.py -v` -- all tests pass
- `pytest tests/unit/cli/ -v` -- no regressions
- `ruff check src/astraea/learning/dspy_optimizer.py src/astraea/cli/app.py src/astraea/cli/display.py`
- `python -m astraea.cli.app --help` -- shows learn-ingest, learn-stats, learn-optimize commands
</verification>

<success_criteria>
- DSPy optimizer builds trainset from stored examples and compiles when sufficient data exists
- learn-ingest loads review sessions and populates learning stores
- learn-stats shows accuracy trends and counts
- learn-optimize triggers DSPy compilation with clear feedback
- All existing CLI tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/08-learning-system/08-05-SUMMARY.md`
</output>
