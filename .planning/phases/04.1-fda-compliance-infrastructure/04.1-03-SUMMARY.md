---
phase: 04.1-fda-compliance-infrastructure
plan: 03
subsystem: execution
tags: [execution-pipeline, pattern-handlers, dataset-executor, sdtm-transforms]
depends_on:
  requires: ["04.1-01", "04.1-02"]
  provides: ["DatasetExecutor", "CrossDomainContext", "ExecutionError", "PATTERN_HANDLERS"]
  affects: ["05", "06", "07"]
tech-stack:
  added: []
  patterns: ["pattern-handler dispatch registry", "priority-ordered execution pipeline", "critical vs non-critical error handling"]
key-files:
  created:
    - src/astraea/execution/__init__.py
    - src/astraea/execution/pattern_handlers.py
    - src/astraea/execution/executor.py
    - tests/unit/execution/__init__.py
    - tests/unit/execution/test_pattern_handlers.py
    - tests/unit/execution/test_executor.py
  modified: []
decisions:
  - id: "D-04.1-03-01"
    summary: "generate_usubjid_column uses studyid_value/siteid_col/subjid_col parameter names (not study_id/site_col/subject_col)"
  - id: "D-04.1-03-02"
    summary: "LOOKUP_RECODE maps preferred_term -> submission_value and submission_value -> submission_value for bidirectional CT matching"
  - id: "D-04.1-03-03"
    summary: "Critical variables (STUDYID, DOMAIN, USUBJID) raise ExecutionError on failure; all others log warning and set to None"
metrics:
  duration: "6 minutes"
  completed: "2026-02-27"
  tests-added: 22
  tests-total: 892
---

# Phase 4.1 Plan 03: Dataset Execution Pipeline Summary

**One-liner:** Pattern-dispatched execution pipeline that transforms DomainMappingSpec + raw DataFrames into SDTM DataFrames with --DY, --SEQ, EPOCH, and column ordering.

## What Was Built

### Task 1: Pattern Handler Functions
Created `src/astraea/execution/pattern_handlers.py` with 9 handler functions (one per MappingPattern enum value) and a dispatch registry:

- **handle_assign**: Returns constant value Series for all rows
- **handle_direct**: Copies source column directly
- **handle_rename**: Delegates to handle_direct (rename happens at assignment)
- **handle_reformat**: Applies registered transform (e.g., sas_datetime_to_iso) via .map()
- **handle_lookup_recode**: Maps values through CT codelist (preferred_term -> submission_value)
- **handle_derivation**: Handles USUBJID generation and registered transforms
- **handle_combine**: Delegates to handle_derivation for USUBJID; stubs for other patterns
- **handle_split/handle_transpose**: Stubs returning None series (deferred to Phase 5/6)

All handlers share signature: `(df, mapping, **kwargs) -> pd.Series`

### Task 2: DatasetExecutor Class
Created `src/astraea/execution/executor.py` with the core execution pipeline:

- **DatasetExecutor.execute()**: Main method transforming spec + raw data into SDTM DataFrame
- **CrossDomainContext**: Pydantic model carrying RFSTDTC lookup, SE data, visit mapping
- **ExecutionError**: Custom exception for critical mapping failures

Execution pipeline steps (in order):
1. Merge raw DataFrames (concat if multiple sources)
2. Apply mappings by priority: ASSIGN -> DIRECT/RENAME -> REFORMAT -> LOOKUP_RECODE -> DERIVATION/COMBINE
3. Derive --DY from cross-domain RFSTDTC
4. Assign EPOCH from SE domain data
5. Assign VISITNUM/VISIT from visit mapping
6. Generate --SEQ for non-DM domains
7. Enforce variable column order from spec
8. Drop unmapped columns
9. Sort rows by domain key variables

## Decisions Made

| ID | Decision | Rationale |
|----|----------|-----------|
| D-04.1-03-01 | generate_usubjid_column parameter alignment | Matched existing function signature: studyid_value, siteid_col, subjid_col |
| D-04.1-03-02 | Bidirectional CT recode dict | Maps both preferred_term->submission_value and identity to handle both raw display names and submission values in source data |
| D-04.1-03-03 | Critical vs non-critical error strategy | STUDYID/DOMAIN/USUBJID failures are fatal (ExecutionError); all other variable failures are logged and set to None to allow partial execution |

## Deviations from Plan

### Auto-fixed Issues

**1. [Rule 1 - Bug] Fixed generate_usubjid_column parameter names**
- **Found during:** Task 2
- **Issue:** Plan called generate_usubjid_column with study_id/site_col/subject_col but actual function uses studyid_value/siteid_col/subjid_col
- **Fix:** Updated handle_derivation to use correct parameter names
- **Files modified:** src/astraea/execution/pattern_handlers.py
- **Commit:** d5231b6

**2. [Rule 3 - Blocking] Ruff lint violations for ternary and nested if**
- **Found during:** Task 2 verification
- **Issue:** SIM108 (use ternary) and SIM102 (collapse nested if) lint errors
- **Fix:** Refactored to ternary operator and extracted boolean variable
- **Files modified:** src/astraea/execution/executor.py, src/astraea/execution/pattern_handlers.py
- **Commit:** d5231b6

## Test Results

- 13 pattern handler tests (all pass)
- 9 executor tests (all pass)
- 892 total tests passing (up from 870, +22 new)
- 15 skipped (pre-existing LLM integration tests)

## Next Phase Readiness

The execution pipeline is now ready for Phase 5 (Events/Interventions domain expansion). Each domain can create a DomainMappingSpec and pass it through DatasetExecutor.execute() with raw DataFrames to produce SDTM output. SPLIT and TRANSPOSE handlers need implementation in Phase 5/6 for Findings domains.
